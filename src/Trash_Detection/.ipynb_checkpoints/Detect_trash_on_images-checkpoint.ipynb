{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Visualize Trash detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import glob\n",
    "import skimage\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Root directory of the project. \n",
    "# Change in case you want to put the notebook somewhere else.\n",
    "ROOT_DIR = os.getcwd()\n",
    "print(ROOT_DIR)\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from trash import trash\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Path to Trash trained weights\n",
    "TRASH_WEIGHTS_PATH = \"weights/mask_rcnn_trash_0200_030519_large.h5\" #the best\n",
    "\n",
    "print('Weights being used: ', TRASH_WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trash'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = trash.TrashConfig()\n",
    "TRASH_DIR = 'trash'\n",
    "TRASH_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.95\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  1024\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           trash\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                17\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 0\n",
      "Classes: ['BG', 'trash']\n"
     ]
    }
   ],
   "source": [
    "# Load validation dataset\n",
    "dataset = trash.TrashDataset()\n",
    "dataset.load_trash(TRASH_DIR, \"val\")\n",
    "\n",
    "# Must call before using the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights  weights/mask_rcnn_trash_0200_030519_large.h5\n"
     ]
    }
   ],
   "source": [
    "# Load the weights you trained\n",
    "weights_path = os.path.join(ROOT_DIR, TRASH_WEIGHTS_PATH)\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "print(\"Loading weights \", TRASH_WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images\\\\1_test.jpg',\n",
       " 'images\\\\test_2.jpg',\n",
       " 'images\\\\test_3.jpg',\n",
       " 'images\\\\test_4.jpg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get images from the directory of all the test images\n",
    "\n",
    "#TODO: Change this so that it collects the data from the correct dirctory in the pi OR whever the pi sends it to the laptop\n",
    "\n",
    "jpg = glob.glob(\"images/*.jpg\")\n",
    "jpeg = glob.glob(\"images/*.jpeg\")\n",
    "jpg.extend(jpeg)\n",
    "jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run detection on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\\1_test.jpg\n",
      "Processing 1 images\n",
      "image                    shape: (3024, 4032, 3)       min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 4032.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
     ]
    }
   ],
   "source": [
    "# This runs the detection on all images in the directory.\n",
    "\n",
    "for image in jpg:\n",
    "    ##image = jpg[2]\n",
    "    print(image) # Print the image \n",
    "    image_temp = image # Save a temporary variable for image so that we can reread it after \n",
    "    image = skimage.io.imread('{}'.format(image))\n",
    "    listOfPoints = []\n",
    "\n",
    "    def f(x,y):\n",
    "        return (x+y)*np.exp(-5.0*(x**2+y**2))\n",
    "\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=1)\n",
    "\n",
    "    # Display results\n",
    "    ax = get_ax(1)\n",
    "    r = results[0]\n",
    "    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                dataset.class_names, r['scores'], ax=ax,\n",
    "                                title=\"Predictions\")\n",
    "\n",
    "    mask = r['masks']\n",
    "    mask = mask.astype(int)\n",
    "    currentPoint = [(550,2000)]\n",
    "    listOfPoints.append(currentPoint)\n",
    "    \n",
    "    \n",
    "    print(mask.shape)\n",
    "    while(mask.shape[2] != 0):\n",
    "        listOfShortest = []\n",
    "\n",
    "        for i in range(mask.shape[2]):\n",
    "            diffMaskNewArray = np.transpose(np.nonzero(mask[:,:,i] == 1)) # Changes the array so that we have an array of points were the mask is.\n",
    "            shortestPoint = diffMaskNewArray[distance.cdist(currentPoint, diffMaskNewArray, 'euclidean').argmin()] # Finds the closest point in the mask to a given point and stores that point.\n",
    "            distanceToPoint = distance.cdist(currentPoint, [shortestPoint], 'euclidean') # Stores the distance of that point. Currently stores it in a 2D array. Need to find a fix for this later\n",
    "            distanceToPoint = distanceToPoint[0][0] #The value is currently written in a 2D array, this takes the value from that 2D array and stores it.\n",
    "            print(distanceToPoint)\n",
    "            print(shortestPoint)\n",
    "            listOfShortest.append([shortestPoint,distanceToPoint,i]) # Add the point to a list of shortest. This can be changed later to just replace the stored value if the new one is closer.\n",
    "            image = image_temp\n",
    "            temp = skimage.io.imread('{}'.format(image))\n",
    "\n",
    "            ## For loop to draw the masks on the original image\n",
    "            for j in range(temp.shape[2]):\n",
    "                temp[:,:,j] = temp[:,:,j] * mask[:,:,i]\n",
    "\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(temp)\n",
    "            x = shortestPoint[0]\n",
    "            y = shortestPoint[1]\n",
    "            y,x = x,y ##Swap the x,y value of our point for printing\n",
    "            shortestPoint = [x,y]\n",
    "            plt.scatter(x,y)\n",
    "            plt.scatter(currentPoint[0][1],currentPoint[0][0])\n",
    "            plt.plot([currentPoint[0][1],x], [currentPoint[0][0],y], linewidth=3)\n",
    "            plt.show()\n",
    "\n",
    "        print(listOfShortest)\n",
    "        absoluteShortest = min(listOfShortest, key=lambda x: x[1])\n",
    "        print(\"Shortest point is \" + str(absoluteShortest[0]) + \" and the distance to it is: \" + str(absoluteShortest[1])) ##Print the distance to the shortest point.\n",
    "        print(absoluteShortest[2])\n",
    "        mask = np.delete(mask,absoluteShortest[2], 2)\n",
    "        currentPoint = [(absoluteShortest[0][0],absoluteShortest[0][1])]\n",
    "        listOfPoints.append(currentPoint)\n",
    "        \n",
    "\n",
    "        #for i in range(mask.shape[2]):\n",
    "        #        temp[:,:,j] = temp[:,:,j] * mask[:,:,i]\n",
    "        print(\"Done\")\n",
    "    image = image_temp\n",
    "    temp = skimage.io.imread('{}'.format(image))\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(temp)\n",
    "    plt.scatter(*zip(*listOfPoints[0]))\n",
    "    plt.show\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
